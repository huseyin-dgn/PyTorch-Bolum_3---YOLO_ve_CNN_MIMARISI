{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edfb29fd",
   "metadata": {},
   "source": [
    "# 🔹 YOLO Mimarisi (Genel Katmanlar)\n",
    "\n",
    "## Backbone\n",
    "- Görüntüden özellikleri çıkarır (feature extraction).  \n",
    "- Örnek: CSPDarknet, CSPNet, veya YOLOv8’de kullanılan **CSPDarknet/TorchVision temelli CNN**.\n",
    "\n",
    "## Neck\n",
    "- Özellikleri birleştirir ve farklı ölçeklerdeki nesneleri algılar.  \n",
    "- Kullanılan yapılar: **Feature Pyramid Network (FPN)** veya **PAN (Path Aggregation Network)**.\n",
    "\n",
    "## Head\n",
    "- Son katman, **bounding box** ve **sınıf tahminlerini** üretir.  \n",
    "- Her grid hücresine birkaç anchor box atanır ve o hücre için olası nesneler tahmin edilir.\n",
    "\n",
    "\n",
    "# 🔹 YOLO’nun Çalışma Prensibi\n",
    "\n",
    "1. Görüntü **SxS** boyutunda bir ızgaraya bölünür.  \n",
    "2. Her hücre bir nesnenin merkezini içeriyorsa:\n",
    "   - Bounding box koordinatları (**x, y, w, h**)  \n",
    "   - Nesneye ait sınıf olasılıkları  \n",
    "   - Güven skoru  \n",
    "   hesaplanır.  \n",
    "3. Bu tahminler birleştirilir → **NMS (Non-Maximum Suppression)** ile çakışan kutular temizlenir.\n",
    "\n",
    "\n",
    "# 🔹 YOLOv8 Öne Çıkan Özellikleri\n",
    "\n",
    "- **Tek model:** Detection, Segmentation ve Classification aynı çatı altında.  \n",
    "- **Anchor-free detection:** Daha hızlı ve hafif modeller oluşturulabiliyor.  \n",
    "- Küçük modeller (n, s) → hızlı, gömülü cihazlarda kullanılabilir.  \n",
    "- Büyük modeller (l, x) → daha doğru ama ağır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caa350d",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf32524",
   "metadata": {},
   "source": [
    "## Mesela YOLO bu kordinatları nasıl öğreniyor ya da nerden biliyor ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c41e140",
   "metadata": {},
   "source": [
    "# 🔹 1. Grid Mantığı\n",
    "- YOLO bir görüntüyü **SxS ızgarasına** böler.  \n",
    "  Örneğin, 640x640’lık bir resim → 20x20 ızgara hücresi.  \n",
    "- Her hücre, sorumlu olduğu alanın merkezinde nesne olup olmadığını tahmin eder.\n",
    "\n",
    "\n",
    "\n",
    "# 🔹 2. Bounding Box Tahmini\n",
    "- Her hücre **B tane bounding box** tahmin eder. Her kutu için:\n",
    "  - **x, y** → kutu merkezinin hücreye göre koordinatı (0–1 arasında normalize)  \n",
    "  - **w, h** → kutunun genişlik ve yüksekliği (resme göre normalize)  \n",
    "  - **confidence score** → bu kutuda nesne var mı, güven seviyesi  \n",
    "\n",
    "- Bu değerler, CNN’in son katmanında öğrenilen **feature map** üzerinden doğrudan tahmin edilir.  \n",
    "- Örn: YOLO “yol” sınıfını tanıyorsa, feature map aktivasyonlarından nesnenin yerini ve boyutunu öğrenir.\n",
    "\n",
    "\n",
    "\n",
    "# 🔹 3. Sınıf Tahmini\n",
    "- Her kutu ayrıca **sınıf olasılıklarını** tahmin eder (softmax veya sigmoid).  \n",
    "- Örn: `[tumsek, kaldirim, yol_calismasi] → [0.1, 0.8, 0.05]` → en yüksek olasılık seçilir.\n",
    "\n",
    "\n",
    "\n",
    "# 🔹 4. Non-Maximum Suppression (NMS)\n",
    "- Birden fazla kutu aynı nesneyi tahmin ederse → çakışan kutulardan en yüksek güven skoru olan seçilir.  \n",
    "- Böylece aynı nesne için birden fazla bounding box çizilmez.\n",
    "\n",
    "\n",
    "\n",
    "# 🔹 5. Özel Sınıflar (Yol, Tümsek, Kaldırım)\n",
    "- COCO’da yok → senin **özel datasetin** üzerinden model öğrenir.  \n",
    "- Eğitim sırasında:  \n",
    "  - YOLO feature map’e bakar → “bu aktivasyonlar yol veya tümsek nesnesine ait”  \n",
    "  - Sonuç: tahmin ettiği **koordinatlar ve sınıf**.\n",
    "\n",
    "📌 **Özet:**  \n",
    "- YOLO herhangi bir nesnenin koordinatlarını **önceden bilmez**, CNN feature map üzerinden öğrenir.  \n",
    "- Sen dataset ile modeline örnekleri gösterdikçe “yol nerede, tümsek nerede” öğrenilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cef632",
   "metadata": {},
   "source": [
    "---\n",
    "## YOLO'nun kod mantığına gelin beraber bakalım."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc77be00",
   "metadata": {},
   "source": [
    "### 🔹 1. Grid ve Feature Map\n",
    "\n",
    "* YOLO, resmi önce bir CNN üzerinden geçirir ve feature map çıkarır:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f7a2216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature map boyutu: torch.Size([1, 16, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Basit bir feature extractor\n",
    "class SimpleBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3, 16, 3, padding=1)  # RGB -> 16 feature map\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv(x))\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "# Örnek giriş\n",
    "x = torch.randn(1, 3, 64, 64)  # 1 resim, 3 kanal, 64x64\n",
    "backbone = SimpleBackbone()\n",
    "feature_map = backbone(x)\n",
    "print(\"Feature map boyutu:\", feature_map.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357d9b3",
   "metadata": {},
   "source": [
    " * Çıktı shape: [batch, channels, height, width]\n",
    "\n",
    "* Bu height x width, YOLO’nun grid mantığına karşılık gelir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba30e82",
   "metadata": {},
   "source": [
    "### 🔹 2. Bounding Box Tahmini\n",
    "\n",
    "* Her grid hücresi için B adet kutu tahmin edilir.\n",
    "\n",
    "* Kutular için x, y, w, h ve confidence skorları hesaplanır:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05fd95cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred shape: torch.Size([1, 13, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "B = 2  # hücre başına 2 tahmin\n",
    "num_classes = 3  # örn: tumsek, kaldirim, yol_calismasi\n",
    "\n",
    "# Basit head: bounding box + class tahmini\n",
    "head = nn.Conv2d(16, B*5 + num_classes, 1)  # 5 -> x,y,w,h,conf\n",
    "pred = head(feature_map)\n",
    "print(\"Pred shape:\", pred.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687fbb59",
   "metadata": {},
   "source": [
    "* pred.shape → [batch, B*5+num_classes, H, W]\n",
    "\n",
    "* Her hücreye karşılık gelen tüm tahminler feature map’ten çıkarılır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741892ec",
   "metadata": {},
   "source": [
    "### 🔹 3. Tahminleri Grid’e Yerleştirme\n",
    "\n",
    "* YOLO grid hücreleri üzerinden normalize edilmiş koordinatları çıkarır:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37801160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Örnek: H=32, W=32\n",
    "H, W = feature_map.shape[2:]\n",
    "pred = pred.permute(0,2,3,1)  # [batch, H, W, B*5+num_classes]\n",
    "# Artık her hücre için B kutu ve class skorları hazır\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff05bfbc",
   "metadata": {},
   "source": [
    "* x,y → hücre içi offset olarak normalize edilir\n",
    "\n",
    "* w,h → resme göre normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036b677f",
   "metadata": {},
   "source": [
    "### 🔹 4. NMS ve Sınıf Seçimi\n",
    "\n",
    "* Aynı nesne birden fazla kutu ile tahmin edilirse Non-Maximum Suppression (NMS) uygulanır:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20214cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seçilen kutular: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.ops import nms\n",
    "\n",
    "boxes = torch.tensor([[10,10,50,50],[12,12,48,48]], dtype=torch.float)\n",
    "scores = torch.tensor([0.9, 0.85])\n",
    "keep = nms(boxes, scores, iou_threshold=0.5)\n",
    "print(\"Seçilen kutular:\", keep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc1547c",
   "metadata": {},
   "source": [
    "* Bu sayede en iyi tahmin kutusu seçilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc33513",
   "metadata": {},
   "source": [
    "```python :\n",
    "💡 Özet:\n",
    "\n",
    "Görüntü → CNN → feature map\n",
    "\n",
    "Feature map → Head → B box + confidence + sınıf\n",
    "\n",
    "Grid hücrelerine dağıt → normalize edilmiş koordinatlar\n",
    "\n",
    "NMS → fazlalıkları temizle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b6ff9",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# YOLO Modeli Katmanları"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b65a5",
   "metadata": {},
   "source": [
    "###  Backbone\n",
    "\n",
    "* Görüntüden özellik haritası çıkarır (feature map).\n",
    "\n",
    "* Bu katmanda kontrast, kenar, doku gibi düşük seviye özellikler öğrenilir.\n",
    "\n",
    "Örnekler: CSPDarknet, ResNet, Darknet-53\n",
    "\n",
    "* Kod örneği:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a26a0",
   "metadata": {},
   "source": [
    "```bash \n",
    "import torch.nn as nn\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cc3b54",
   "metadata": {},
   "source": [
    "###  Neck\n",
    "\n",
    "* Özellik haritalarını birleştirir ve farklı ölçeklerdeki nesneleri yakalar.\n",
    "\n",
    "* Kullanılan yapılar: FPN (Feature Pyramid Network), PAN (Path Aggregation Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c07d18",
   "metadata": {},
   "source": [
    "###  Head\n",
    "\n",
    "* Bounding box ve sınıf tahmini yapan son katmandır.\n",
    "\n",
    "* Grid hücreleri üzerinden B adet tahmin kutusu üretir:\n",
    "\n",
    "```bash\n",
    "x, y → kutu merkezi\n",
    "\n",
    "w, h → kutu boyutu\n",
    "\n",
    "confidence → nesne var mı?\n",
    "\n",
    "sınıf olasılıkları → softmax/sigmoid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b307e",
   "metadata": {},
   "source": [
    "```python \n",
    "class Head(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, B=2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, B*5 + num_classes, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4552ea",
   "metadata": {},
   "source": [
    "##  YOLO Modelinin Tam Yapısı\n",
    "\n",
    "* Backbone → Neck → Head şeklinde birleştirilir.\n",
    "\n",
    "```python \n",
    "\n",
    "class YOLO(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.backbone = Backbone()\n",
    "        # Basit bir neck örneği (identity)\n",
    "        self.neck = nn.Identity()\n",
    "        self.head = Head(64, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.neck(x)\n",
    "        x = self.head(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4702ea",
   "metadata": {},
   "source": [
    "* Çıktı shape: [batch_size, B*5 + num_classes, H, W]\n",
    "\n",
    "* Bu çıktı her grid hücresi için bounding box ve sınıf bilgilerini içerir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa24af2",
   "metadata": {},
   "source": [
    "### Tahminlerin İşlenmesi\n",
    "\n",
    "* Feature map → Head → grid hücrelerine dağıtılır\n",
    "\n",
    "* Koordinatlar normalize edilir\n",
    "\n",
    "* NMS uygulanır → çakışan kutular temizlenir\n",
    "\n",
    "* Sınıf olasılığına göre en yüksek tahmin seçilir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5033c9",
   "metadata": {},
   "source": [
    "## 💡 Özet:\n",
    "\n",
    "* YOLO modeli bir CNN tabanlı feature extractor + özellikleri birleştiren neck + bounding box ve sınıf tahminleri yapan head üçlüsünden oluşur.\n",
    "\n",
    "* Kendi datasetinle bu yapıyı eğiterek yol, tümsek, kaldırım gibi özel nesneleri tanıyabilirsin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e07d51",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3270511d",
   "metadata": {},
   "source": [
    "## Yolo Crop İşlemi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079045c7",
   "metadata": {},
   "source": [
    "# 🔹 Crop İşlemi (YOLO Dataset)\n",
    "\n",
    "## 1️⃣ Crop’un Amacı\n",
    "- **Nesneyi büyütmek ve odaklanmak**: Küçük nesneler (tümsek, çukur, çatlak) resmin küçük bir bölümünde olabilir. Crop ile modelin bu nesneleri daha net görmesini sağlarsın.  \n",
    "- **Veri artırma**: Farklı crop bölgeleri oluşturarak dataset’i çeşitlendirebilirsin.  \n",
    "- **Gereksiz alanları azaltmak**: Eğer resmin büyük kısmı sadece yol ve boş alan ise, crop ile sadece önemli bölgeyi kullanabilirsin.  \n",
    "\n",
    "\n",
    "\n",
    "## 2️⃣ Crop Yöntemleri\n",
    "### A) Etiket Bazlı Crop\n",
    "- YOLO etiketi (`.txt`) üzerinden xmin, ymin, xmax, ymax koordinatlarını kullanırsın.  \n",
    "- Crop işlemi direkt bu koordinatlarla yapılır.  \n",
    "\n",
    "### B) Sabit Bölge Crop\n",
    "- Eğer tümsek/çukur her zaman resmin aynı bölgesindeyse, **sabit bir crop bölgesi** belirleyebilirsin.  \n",
    "\n",
    "### C) Rastgele Crop (Augmentation)\n",
    "- Küçük rastgele kesitler alıp hem nesneyi hem biraz çevresini dahil edersin.  \n",
    "- Modelin farklı açılar ve pozisyonlar görmesini sağlar.  \n",
    "\n",
    "\n",
    "\n",
    "## 3️⃣ Crop + YOLO Etiketleri\n",
    "- Crop sonrası **etiketleri normalize etmeyi unutma**.  \n",
    "- Örnek:\n",
    "  - Orijinal resim: 640x640  \n",
    "  - Bounding box: xmin=50, ymin=60, xmax=150, ymax=120  \n",
    "  - Crop: 50:150, 60:120 → crop boyutu 100x60  \n",
    "  - Yeni bounding box → crop içindeki koordinatlara göre normalize edilir:\n",
    "    ```\n",
    "    x_center = 0.5\n",
    "    y_center = 0.5\n",
    "    width = 1.0\n",
    "    height = 1.0\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed53cf",
   "metadata": {},
   "source": [
    "---\n",
    "## Mesela bir görselde yoldaki çatlaklar var.Biz bunları neye göre kırpacağız ? \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26523a86",
   "metadata": {},
   "source": [
    "# 🔹 Çatlakları Crop Etme Mantığı (YOLO Dataset)\n",
    "\n",
    "## 1️⃣ Öncelik: Nesnenin Alanını Belirlemek\n",
    "- Kırpma işlemi için **nesnenin bulunduğu alan** temel alınır.  \n",
    "- YOLO dataset’inde bu alanlar **etiket dosyalarında (.txt) xmin, ymin, xmax, ymax** olarak verilir.  \n",
    "- Çatlaklar genellikle uzun ve ince olduğu için birden fazla kutu ile etiketlenmiş olabilir → **her kutuyu ayrı crop veya birleştirilmiş crop** yapabilirsin.\n",
    "\n",
    "\n",
    "\n",
    "## 2️⃣ Crop Mantığı\n",
    "### A) Tek Kutulu Crop\n",
    "- Çatlak küçük ve tek bir bbox ile kapsanabiliyorsa:\n",
    "  - `xmin, ymin, xmax, ymax` kullan → crop  \n",
    "  - Kırpılmış resim sadece çatlağı içerir  \n",
    "\n",
    "### B) Birden Fazla Kutulu Crop\n",
    "- Çatlak uzun veya birden fazla bbox ile bölünmüşse:\n",
    "  - Tüm ilgili bbox’ları kapsayan **tek büyük crop** oluştur  \n",
    "  - Veya her bbox’ı ayrı crop al, farklı örnekler olarak kullan  \n",
    "\n",
    "### C) Crop + Padding\n",
    "- Crop sırasında biraz **çevre bırakmak** (padding) faydalıdır:  \n",
    "  - Model nesnenin kontekstini görür → yol, çevre dokusu  \n",
    "  - Özellikle çatlak gibi uzun nesnelerde önemlidir  \n",
    "\n",
    "\n",
    "\n",
    "## 3️⃣ Normalizasyon ve Etiket Güncelleme\n",
    "- Crop sonrası bbox koordinatlarını **yeni crop boyutuna göre normalize et**:  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df1b4a4",
   "metadata": {},
   "source": [
    "```python \n",
    "x_center_new = (x_center - crop_xmin) / crop_width\n",
    "y_center_new = (y_center - crop_ymin) / crop_height\n",
    "width_new = width / crop_width\n",
    "height_new = height / crop_height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3b9603",
   "metadata": {},
   "source": [
    "- Böylece model doğru koordinatları öğrenir.\n",
    "\n",
    "\n",
    "## 4️⃣ Özet Strateji\n",
    "1. Her çatlak için etiket dosyalarını kontrol et.  \n",
    "2. Crop alanını belirle (tek bbox veya birden fazla bbox’ı kapsayan alan).  \n",
    "3. Crop sırasında padding bırak → yol ve çevre bilgisi kaybolmasın.  \n",
    "4. Yeni crop için etiketleri normalize et.  \n",
    "5. Dataset’i çeşitlendirmek için farklı crop bölgeleri ve augmentation ekle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794bc333",
   "metadata": {},
   "source": [
    "----\n",
    "## Görüntüde yolda bulunan çatlak var.Ben bu çatlağı nasıl bulacağım.Mesela kare şeklinde değil de uzun sola yatık halde ? En optimum etiketleme yçntemi nedir ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58586baa",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c968f5dc",
   "metadata": {},
   "source": [
    "# 🔹 Yol Üzerindeki Uzun ve Yatık Çatlakların Etiketlenmesi\n",
    "\n",
    "## 1️⃣ Sorun\n",
    "- Standart YOLO bounding box’ları **dikdörtgen**.  \n",
    "- Çatlaklar uzun ve ince → dikdörtgen kutu çok büyük olabilir veya boş alanı kapsayabilir.  \n",
    "- Bu durum modelin öğrenmesini zorlaştırır.\n",
    "\n",
    "\n",
    "## 2️⃣ Optimum Etiketleme Yöntemleri\n",
    "\n",
    "### A) Rotated Bounding Box (Dönebilir Kutular)\n",
    "- Bazı YOLO sürümleri **rotated bbox** destekler.  \n",
    "- Çatlağı **uzun eksenine göre döndürerek** kutula → model daha doğru öğrenir.  \n",
    "\n",
    "### B) Birden Fazla Küçük Dikdörtgen\n",
    "- Çatlak çok uzun ise, onu **birden fazla küçük dikdörtgen bbox’a böl**.  \n",
    "- Örn: 3-4 parçaya böl → her parça ayrı etiketlenir.  \n",
    "- Avantaj: Model uzun ve ince nesneleri daha iyi öğrenir.\n",
    "\n",
    "### C) Minimum Dikdörtgen\n",
    "- Çatlağı çevreleyen **en küçük dikdörtgeni** çiz.  \n",
    "- Eğer çok yatıksa, kutu biraz **padding** ile genişletilebilir → model hem nesneyi hem biraz çevresini görür.  \n",
    "\n",
    "\n",
    "## 3️⃣ Crop ve Eğitim Açısından\n",
    "- Uzun çatlağı tek crop içine al → padding bırak.  \n",
    "- Veya parçalar halinde crop al → dataset’i çeşitlendirmiş olursun.  \n",
    "- Normalize ederken her bbox’un **crop içindeki koordinatlarını** doğru hesapla.\n",
    "\n",
    "\n",
    "## 4️⃣ Özet Strateji\n",
    "1. Çatlak uzun ve yatık → tek dikdörtgen veya birden fazla küçük dikdörtgen.  \n",
    "2. Padding bırak → yol ve çevre bilgisini kaybetme.  \n",
    "3. Rotated bbox destekleyen YOLO sürümü kullan → en doğru sonuç.  \n",
    "4. Dataset’i çeşitlendirmek için parçalama ve augmentation uygula.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f470d55",
   "metadata": {},
   "source": [
    "### Şimdi sizlerle bir yolda bulunan tümseklerin analizini yapcağız.Yani yolda bulunan tümsekleri etiketleyeceğiz.Sonrasında ise bu etiketlenmiş verileri YOLO'ya entegre ettirip yol ve tümsek olarak etiketleme yapacağız.Sonrasında ise buradan çıkan değerleri CNN modele koyup daha detaylı analizini yapacağız.\n",
    "\n",
    "#### Bu uygulamaya ve çözüme ulaşmak için lütfen şu dosya yoluna gidiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9da26f",
   "metadata": {},
   "source": [
    "```python \n",
    "\n",
    "* YOLO\\YOLO\\Uygulamalar\\Uygulama - 1 (Yol - Tümsek)\\yol_tümsek.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e45e15",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
