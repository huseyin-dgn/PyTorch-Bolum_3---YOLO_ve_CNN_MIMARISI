{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edfb29fd",
   "metadata": {},
   "source": [
    "# ğŸ”¹ YOLO Mimarisi (Genel Katmanlar)\n",
    "\n",
    "## Backbone\n",
    "- GÃ¶rÃ¼ntÃ¼den Ã¶zellikleri Ã§Ä±karÄ±r (feature extraction).  \n",
    "- Ã–rnek: CSPDarknet, CSPNet, veya YOLOv8â€™de kullanÄ±lan **CSPDarknet/TorchVision temelli CNN**.\n",
    "\n",
    "## Neck\n",
    "- Ã–zellikleri birleÅŸtirir ve farklÄ± Ã¶lÃ§eklerdeki nesneleri algÄ±lar.  \n",
    "- KullanÄ±lan yapÄ±lar: **Feature Pyramid Network (FPN)** veya **PAN (Path Aggregation Network)**.\n",
    "\n",
    "## Head\n",
    "- Son katman, **bounding box** ve **sÄ±nÄ±f tahminlerini** Ã¼retir.  \n",
    "- Her grid hÃ¼cresine birkaÃ§ anchor box atanÄ±r ve o hÃ¼cre iÃ§in olasÄ± nesneler tahmin edilir.\n",
    "\n",
    "\n",
    "# ğŸ”¹ YOLOâ€™nun Ã‡alÄ±ÅŸma Prensibi\n",
    "\n",
    "1. GÃ¶rÃ¼ntÃ¼ **SxS** boyutunda bir Ä±zgaraya bÃ¶lÃ¼nÃ¼r.  \n",
    "2. Her hÃ¼cre bir nesnenin merkezini iÃ§eriyorsa:\n",
    "   - Bounding box koordinatlarÄ± (**x, y, w, h**)  \n",
    "   - Nesneye ait sÄ±nÄ±f olasÄ±lÄ±klarÄ±  \n",
    "   - GÃ¼ven skoru  \n",
    "   hesaplanÄ±r.  \n",
    "3. Bu tahminler birleÅŸtirilir â†’ **NMS (Non-Maximum Suppression)** ile Ã§akÄ±ÅŸan kutular temizlenir.\n",
    "\n",
    "\n",
    "# ğŸ”¹ YOLOv8 Ã–ne Ã‡Ä±kan Ã–zellikleri\n",
    "\n",
    "- **Tek model:** Detection, Segmentation ve Classification aynÄ± Ã§atÄ± altÄ±nda.  \n",
    "- **Anchor-free detection:** Daha hÄ±zlÄ± ve hafif modeller oluÅŸturulabiliyor.  \n",
    "- KÃ¼Ã§Ã¼k modeller (n, s) â†’ hÄ±zlÄ±, gÃ¶mÃ¼lÃ¼ cihazlarda kullanÄ±labilir.  \n",
    "- BÃ¼yÃ¼k modeller (l, x) â†’ daha doÄŸru ama aÄŸÄ±r.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caa350d",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf32524",
   "metadata": {},
   "source": [
    "## Mesela YOLO bu kordinatlarÄ± nasÄ±l Ã¶ÄŸreniyor ya da nerden biliyor ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c41e140",
   "metadata": {},
   "source": [
    "# ğŸ”¹ 1. Grid MantÄ±ÄŸÄ±\n",
    "- YOLO bir gÃ¶rÃ¼ntÃ¼yÃ¼ **SxS Ä±zgarasÄ±na** bÃ¶ler.  \n",
    "  Ã–rneÄŸin, 640x640â€™lÄ±k bir resim â†’ 20x20 Ä±zgara hÃ¼cresi.  \n",
    "- Her hÃ¼cre, sorumlu olduÄŸu alanÄ±n merkezinde nesne olup olmadÄ±ÄŸÄ±nÄ± tahmin eder.\n",
    "\n",
    "\n",
    "\n",
    "# ğŸ”¹ 2. Bounding Box Tahmini\n",
    "- Her hÃ¼cre **B tane bounding box** tahmin eder. Her kutu iÃ§in:\n",
    "  - **x, y** â†’ kutu merkezinin hÃ¼creye gÃ¶re koordinatÄ± (0â€“1 arasÄ±nda normalize)  \n",
    "  - **w, h** â†’ kutunun geniÅŸlik ve yÃ¼ksekliÄŸi (resme gÃ¶re normalize)  \n",
    "  - **confidence score** â†’ bu kutuda nesne var mÄ±, gÃ¼ven seviyesi  \n",
    "\n",
    "- Bu deÄŸerler, CNNâ€™in son katmanÄ±nda Ã¶ÄŸrenilen **feature map** Ã¼zerinden doÄŸrudan tahmin edilir.  \n",
    "- Ã–rn: YOLO â€œyolâ€ sÄ±nÄ±fÄ±nÄ± tanÄ±yorsa, feature map aktivasyonlarÄ±ndan nesnenin yerini ve boyutunu Ã¶ÄŸrenir.\n",
    "\n",
    "\n",
    "\n",
    "# ğŸ”¹ 3. SÄ±nÄ±f Tahmini\n",
    "- Her kutu ayrÄ±ca **sÄ±nÄ±f olasÄ±lÄ±klarÄ±nÄ±** tahmin eder (softmax veya sigmoid).  \n",
    "- Ã–rn: `[tumsek, kaldirim, yol_calismasi] â†’ [0.1, 0.8, 0.05]` â†’ en yÃ¼ksek olasÄ±lÄ±k seÃ§ilir.\n",
    "\n",
    "\n",
    "\n",
    "# ğŸ”¹ 4. Non-Maximum Suppression (NMS)\n",
    "- Birden fazla kutu aynÄ± nesneyi tahmin ederse â†’ Ã§akÄ±ÅŸan kutulardan en yÃ¼ksek gÃ¼ven skoru olan seÃ§ilir.  \n",
    "- BÃ¶ylece aynÄ± nesne iÃ§in birden fazla bounding box Ã§izilmez.\n",
    "\n",
    "\n",
    "\n",
    "# ğŸ”¹ 5. Ã–zel SÄ±nÄ±flar (Yol, TÃ¼msek, KaldÄ±rÄ±m)\n",
    "- COCOâ€™da yok â†’ senin **Ã¶zel datasetin** Ã¼zerinden model Ã¶ÄŸrenir.  \n",
    "- EÄŸitim sÄ±rasÄ±nda:  \n",
    "  - YOLO feature mapâ€™e bakar â†’ â€œbu aktivasyonlar yol veya tÃ¼msek nesnesine aitâ€  \n",
    "  - SonuÃ§: tahmin ettiÄŸi **koordinatlar ve sÄ±nÄ±f**.\n",
    "\n",
    "ğŸ“Œ **Ã–zet:**  \n",
    "- YOLO herhangi bir nesnenin koordinatlarÄ±nÄ± **Ã¶nceden bilmez**, CNN feature map Ã¼zerinden Ã¶ÄŸrenir.  \n",
    "- Sen dataset ile modeline Ã¶rnekleri gÃ¶sterdikÃ§e â€œyol nerede, tÃ¼msek neredeâ€ Ã¶ÄŸrenilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cef632",
   "metadata": {},
   "source": [
    "---\n",
    "## YOLO'nun kod mantÄ±ÄŸÄ±na gelin beraber bakalÄ±m."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc77be00",
   "metadata": {},
   "source": [
    "### ğŸ”¹ 1. Grid ve Feature Map\n",
    "\n",
    "* YOLO, resmi Ã¶nce bir CNN Ã¼zerinden geÃ§irir ve feature map Ã§Ä±karÄ±r:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f7a2216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature map boyutu: torch.Size([1, 16, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Basit bir feature extractor\n",
    "class SimpleBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3, 16, 3, padding=1)  # RGB -> 16 feature map\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv(x))\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "# Ã–rnek giriÅŸ\n",
    "x = torch.randn(1, 3, 64, 64)  # 1 resim, 3 kanal, 64x64\n",
    "backbone = SimpleBackbone()\n",
    "feature_map = backbone(x)\n",
    "print(\"Feature map boyutu:\", feature_map.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357d9b3",
   "metadata": {},
   "source": [
    " * Ã‡Ä±ktÄ± shape: [batch, channels, height, width]\n",
    "\n",
    "* Bu height x width, YOLOâ€™nun grid mantÄ±ÄŸÄ±na karÅŸÄ±lÄ±k gelir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba30e82",
   "metadata": {},
   "source": [
    "### ğŸ”¹ 2. Bounding Box Tahmini\n",
    "\n",
    "* Her grid hÃ¼cresi iÃ§in B adet kutu tahmin edilir.\n",
    "\n",
    "* Kutular iÃ§in x, y, w, h ve confidence skorlarÄ± hesaplanÄ±r:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05fd95cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred shape: torch.Size([1, 13, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "B = 2  # hÃ¼cre baÅŸÄ±na 2 tahmin\n",
    "num_classes = 3  # Ã¶rn: tumsek, kaldirim, yol_calismasi\n",
    "\n",
    "# Basit head: bounding box + class tahmini\n",
    "head = nn.Conv2d(16, B*5 + num_classes, 1)  # 5 -> x,y,w,h,conf\n",
    "pred = head(feature_map)\n",
    "print(\"Pred shape:\", pred.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687fbb59",
   "metadata": {},
   "source": [
    "* pred.shape â†’ [batch, B*5+num_classes, H, W]\n",
    "\n",
    "* Her hÃ¼creye karÅŸÄ±lÄ±k gelen tÃ¼m tahminler feature mapâ€™ten Ã§Ä±karÄ±lÄ±r."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741892ec",
   "metadata": {},
   "source": [
    "### ğŸ”¹ 3. Tahminleri Gridâ€™e YerleÅŸtirme\n",
    "\n",
    "* YOLO grid hÃ¼creleri Ã¼zerinden normalize edilmiÅŸ koordinatlarÄ± Ã§Ä±karÄ±r:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37801160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ã–rnek: H=32, W=32\n",
    "H, W = feature_map.shape[2:]\n",
    "pred = pred.permute(0,2,3,1)  # [batch, H, W, B*5+num_classes]\n",
    "# ArtÄ±k her hÃ¼cre iÃ§in B kutu ve class skorlarÄ± hazÄ±r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff05bfbc",
   "metadata": {},
   "source": [
    "* x,y â†’ hÃ¼cre iÃ§i offset olarak normalize edilir\n",
    "\n",
    "* w,h â†’ resme gÃ¶re normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036b677f",
   "metadata": {},
   "source": [
    "### ğŸ”¹ 4. NMS ve SÄ±nÄ±f SeÃ§imi\n",
    "\n",
    "* AynÄ± nesne birden fazla kutu ile tahmin edilirse Non-Maximum Suppression (NMS) uygulanÄ±r:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20214cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeÃ§ilen kutular: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "from torchvision.ops import nms\n",
    "\n",
    "boxes = torch.tensor([[10,10,50,50],[12,12,48,48]], dtype=torch.float)\n",
    "scores = torch.tensor([0.9, 0.85])\n",
    "keep = nms(boxes, scores, iou_threshold=0.5)\n",
    "print(\"SeÃ§ilen kutular:\", keep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc1547c",
   "metadata": {},
   "source": [
    "* Bu sayede en iyi tahmin kutusu seÃ§ilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc33513",
   "metadata": {},
   "source": [
    "```python :\n",
    "ğŸ’¡ Ã–zet:\n",
    "\n",
    "GÃ¶rÃ¼ntÃ¼ â†’ CNN â†’ feature map\n",
    "\n",
    "Feature map â†’ Head â†’ B box + confidence + sÄ±nÄ±f\n",
    "\n",
    "Grid hÃ¼crelerine daÄŸÄ±t â†’ normalize edilmiÅŸ koordinatlar\n",
    "\n",
    "NMS â†’ fazlalÄ±klarÄ± temizle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b6ff9",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# YOLO Modeli KatmanlarÄ±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b65a5",
   "metadata": {},
   "source": [
    "###  Backbone\n",
    "\n",
    "* GÃ¶rÃ¼ntÃ¼den Ã¶zellik haritasÄ± Ã§Ä±karÄ±r (feature map).\n",
    "\n",
    "* Bu katmanda kontrast, kenar, doku gibi dÃ¼ÅŸÃ¼k seviye Ã¶zellikler Ã¶ÄŸrenilir.\n",
    "\n",
    "Ã–rnekler: CSPDarknet, ResNet, Darknet-53\n",
    "\n",
    "* Kod Ã¶rneÄŸi:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a26a0",
   "metadata": {},
   "source": [
    "```bash \n",
    "import torch.nn as nn\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cc3b54",
   "metadata": {},
   "source": [
    "###  Neck\n",
    "\n",
    "* Ã–zellik haritalarÄ±nÄ± birleÅŸtirir ve farklÄ± Ã¶lÃ§eklerdeki nesneleri yakalar.\n",
    "\n",
    "* KullanÄ±lan yapÄ±lar: FPN (Feature Pyramid Network), PAN (Path Aggregation Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c07d18",
   "metadata": {},
   "source": [
    "###  Head\n",
    "\n",
    "* Bounding box ve sÄ±nÄ±f tahmini yapan son katmandÄ±r.\n",
    "\n",
    "* Grid hÃ¼creleri Ã¼zerinden B adet tahmin kutusu Ã¼retir:\n",
    "\n",
    "```bash\n",
    "x, y â†’ kutu merkezi\n",
    "\n",
    "w, h â†’ kutu boyutu\n",
    "\n",
    "confidence â†’ nesne var mÄ±?\n",
    "\n",
    "sÄ±nÄ±f olasÄ±lÄ±klarÄ± â†’ softmax/sigmoid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b307e",
   "metadata": {},
   "source": [
    "```python \n",
    "class Head(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, B=2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, B*5 + num_classes, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4552ea",
   "metadata": {},
   "source": [
    "##  YOLO Modelinin Tam YapÄ±sÄ±\n",
    "\n",
    "* Backbone â†’ Neck â†’ Head ÅŸeklinde birleÅŸtirilir.\n",
    "\n",
    "```python \n",
    "\n",
    "class YOLO(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.backbone = Backbone()\n",
    "        # Basit bir neck Ã¶rneÄŸi (identity)\n",
    "        self.neck = nn.Identity()\n",
    "        self.head = Head(64, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.neck(x)\n",
    "        x = self.head(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4702ea",
   "metadata": {},
   "source": [
    "* Ã‡Ä±ktÄ± shape: [batch_size, B*5 + num_classes, H, W]\n",
    "\n",
    "* Bu Ã§Ä±ktÄ± her grid hÃ¼cresi iÃ§in bounding box ve sÄ±nÄ±f bilgilerini iÃ§erir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa24af2",
   "metadata": {},
   "source": [
    "### Tahminlerin Ä°ÅŸlenmesi\n",
    "\n",
    "* Feature map â†’ Head â†’ grid hÃ¼crelerine daÄŸÄ±tÄ±lÄ±r\n",
    "\n",
    "* Koordinatlar normalize edilir\n",
    "\n",
    "* NMS uygulanÄ±r â†’ Ã§akÄ±ÅŸan kutular temizlenir\n",
    "\n",
    "* SÄ±nÄ±f olasÄ±lÄ±ÄŸÄ±na gÃ¶re en yÃ¼ksek tahmin seÃ§ilir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5033c9",
   "metadata": {},
   "source": [
    "## ğŸ’¡ Ã–zet:\n",
    "\n",
    "* YOLO modeli bir CNN tabanlÄ± feature extractor + Ã¶zellikleri birleÅŸtiren neck + bounding box ve sÄ±nÄ±f tahminleri yapan head Ã¼Ã§lÃ¼sÃ¼nden oluÅŸur.\n",
    "\n",
    "* Kendi datasetinle bu yapÄ±yÄ± eÄŸiterek yol, tÃ¼msek, kaldÄ±rÄ±m gibi Ã¶zel nesneleri tanÄ±yabilirsin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e07d51",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3270511d",
   "metadata": {},
   "source": [
    "## Yolo Crop Ä°ÅŸlemi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079045c7",
   "metadata": {},
   "source": [
    "# ğŸ”¹ Crop Ä°ÅŸlemi (YOLO Dataset)\n",
    "\n",
    "## 1ï¸âƒ£ Cropâ€™un AmacÄ±\n",
    "- **Nesneyi bÃ¼yÃ¼tmek ve odaklanmak**: KÃ¼Ã§Ã¼k nesneler (tÃ¼msek, Ã§ukur, Ã§atlak) resmin kÃ¼Ã§Ã¼k bir bÃ¶lÃ¼mÃ¼nde olabilir. Crop ile modelin bu nesneleri daha net gÃ¶rmesini saÄŸlarsÄ±n.  \n",
    "- **Veri artÄ±rma**: FarklÄ± crop bÃ¶lgeleri oluÅŸturarak datasetâ€™i Ã§eÅŸitlendirebilirsin.  \n",
    "- **Gereksiz alanlarÄ± azaltmak**: EÄŸer resmin bÃ¼yÃ¼k kÄ±smÄ± sadece yol ve boÅŸ alan ise, crop ile sadece Ã¶nemli bÃ¶lgeyi kullanabilirsin.  \n",
    "\n",
    "\n",
    "\n",
    "## 2ï¸âƒ£ Crop YÃ¶ntemleri\n",
    "### A) Etiket BazlÄ± Crop\n",
    "- YOLO etiketi (`.txt`) Ã¼zerinden xmin, ymin, xmax, ymax koordinatlarÄ±nÄ± kullanÄ±rsÄ±n.  \n",
    "- Crop iÅŸlemi direkt bu koordinatlarla yapÄ±lÄ±r.  \n",
    "\n",
    "### B) Sabit BÃ¶lge Crop\n",
    "- EÄŸer tÃ¼msek/Ã§ukur her zaman resmin aynÄ± bÃ¶lgesindeyse, **sabit bir crop bÃ¶lgesi** belirleyebilirsin.  \n",
    "\n",
    "### C) Rastgele Crop (Augmentation)\n",
    "- KÃ¼Ã§Ã¼k rastgele kesitler alÄ±p hem nesneyi hem biraz Ã§evresini dahil edersin.  \n",
    "- Modelin farklÄ± aÃ§Ä±lar ve pozisyonlar gÃ¶rmesini saÄŸlar.  \n",
    "\n",
    "\n",
    "\n",
    "## 3ï¸âƒ£ Crop + YOLO Etiketleri\n",
    "- Crop sonrasÄ± **etiketleri normalize etmeyi unutma**.  \n",
    "- Ã–rnek:\n",
    "  - Orijinal resim: 640x640  \n",
    "  - Bounding box: xmin=50, ymin=60, xmax=150, ymax=120  \n",
    "  - Crop: 50:150, 60:120 â†’ crop boyutu 100x60  \n",
    "  - Yeni bounding box â†’ crop iÃ§indeki koordinatlara gÃ¶re normalize edilir:\n",
    "    ```\n",
    "    x_center = 0.5\n",
    "    y_center = 0.5\n",
    "    width = 1.0\n",
    "    height = 1.0\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed53cf",
   "metadata": {},
   "source": [
    "---\n",
    "## Mesela bir gÃ¶rselde yoldaki Ã§atlaklar var.Biz bunlarÄ± neye gÃ¶re kÄ±rpacaÄŸÄ±z ? \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26523a86",
   "metadata": {},
   "source": [
    "# ğŸ”¹ Ã‡atlaklarÄ± Crop Etme MantÄ±ÄŸÄ± (YOLO Dataset)\n",
    "\n",
    "## 1ï¸âƒ£ Ã–ncelik: Nesnenin AlanÄ±nÄ± Belirlemek\n",
    "- KÄ±rpma iÅŸlemi iÃ§in **nesnenin bulunduÄŸu alan** temel alÄ±nÄ±r.  \n",
    "- YOLO datasetâ€™inde bu alanlar **etiket dosyalarÄ±nda (.txt) xmin, ymin, xmax, ymax** olarak verilir.  \n",
    "- Ã‡atlaklar genellikle uzun ve ince olduÄŸu iÃ§in birden fazla kutu ile etiketlenmiÅŸ olabilir â†’ **her kutuyu ayrÄ± crop veya birleÅŸtirilmiÅŸ crop** yapabilirsin.\n",
    "\n",
    "\n",
    "\n",
    "## 2ï¸âƒ£ Crop MantÄ±ÄŸÄ±\n",
    "### A) Tek Kutulu Crop\n",
    "- Ã‡atlak kÃ¼Ã§Ã¼k ve tek bir bbox ile kapsanabiliyorsa:\n",
    "  - `xmin, ymin, xmax, ymax` kullan â†’ crop  \n",
    "  - KÄ±rpÄ±lmÄ±ÅŸ resim sadece Ã§atlaÄŸÄ± iÃ§erir  \n",
    "\n",
    "### B) Birden Fazla Kutulu Crop\n",
    "- Ã‡atlak uzun veya birden fazla bbox ile bÃ¶lÃ¼nmÃ¼ÅŸse:\n",
    "  - TÃ¼m ilgili bboxâ€™larÄ± kapsayan **tek bÃ¼yÃ¼k crop** oluÅŸtur  \n",
    "  - Veya her bboxâ€™Ä± ayrÄ± crop al, farklÄ± Ã¶rnekler olarak kullan  \n",
    "\n",
    "### C) Crop + Padding\n",
    "- Crop sÄ±rasÄ±nda biraz **Ã§evre bÄ±rakmak** (padding) faydalÄ±dÄ±r:  \n",
    "  - Model nesnenin kontekstini gÃ¶rÃ¼r â†’ yol, Ã§evre dokusu  \n",
    "  - Ã–zellikle Ã§atlak gibi uzun nesnelerde Ã¶nemlidir  \n",
    "\n",
    "\n",
    "\n",
    "## 3ï¸âƒ£ Normalizasyon ve Etiket GÃ¼ncelleme\n",
    "- Crop sonrasÄ± bbox koordinatlarÄ±nÄ± **yeni crop boyutuna gÃ¶re normalize et**:  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df1b4a4",
   "metadata": {},
   "source": [
    "```python \n",
    "x_center_new = (x_center - crop_xmin) / crop_width\n",
    "y_center_new = (y_center - crop_ymin) / crop_height\n",
    "width_new = width / crop_width\n",
    "height_new = height / crop_height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3b9603",
   "metadata": {},
   "source": [
    "- BÃ¶ylece model doÄŸru koordinatlarÄ± Ã¶ÄŸrenir.\n",
    "\n",
    "\n",
    "## 4ï¸âƒ£ Ã–zet Strateji\n",
    "1. Her Ã§atlak iÃ§in etiket dosyalarÄ±nÄ± kontrol et.  \n",
    "2. Crop alanÄ±nÄ± belirle (tek bbox veya birden fazla bboxâ€™Ä± kapsayan alan).  \n",
    "3. Crop sÄ±rasÄ±nda padding bÄ±rak â†’ yol ve Ã§evre bilgisi kaybolmasÄ±n.  \n",
    "4. Yeni crop iÃ§in etiketleri normalize et.  \n",
    "5. Datasetâ€™i Ã§eÅŸitlendirmek iÃ§in farklÄ± crop bÃ¶lgeleri ve augmentation ekle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794bc333",
   "metadata": {},
   "source": [
    "----\n",
    "## GÃ¶rÃ¼ntÃ¼de yolda bulunan Ã§atlak var.Ben bu Ã§atlaÄŸÄ± nasÄ±l bulacaÄŸÄ±m.Mesela kare ÅŸeklinde deÄŸil de uzun sola yatÄ±k halde ? En optimum etiketleme yÃ§ntemi nedir ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58586baa",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c968f5dc",
   "metadata": {},
   "source": [
    "# ğŸ”¹ Yol Ãœzerindeki Uzun ve YatÄ±k Ã‡atlaklarÄ±n Etiketlenmesi\n",
    "\n",
    "## 1ï¸âƒ£ Sorun\n",
    "- Standart YOLO bounding boxâ€™larÄ± **dikdÃ¶rtgen**.  \n",
    "- Ã‡atlaklar uzun ve ince â†’ dikdÃ¶rtgen kutu Ã§ok bÃ¼yÃ¼k olabilir veya boÅŸ alanÄ± kapsayabilir.  \n",
    "- Bu durum modelin Ã¶ÄŸrenmesini zorlaÅŸtÄ±rÄ±r.\n",
    "\n",
    "\n",
    "## 2ï¸âƒ£ Optimum Etiketleme YÃ¶ntemleri\n",
    "\n",
    "### A) Rotated Bounding Box (DÃ¶nebilir Kutular)\n",
    "- BazÄ± YOLO sÃ¼rÃ¼mleri **rotated bbox** destekler.  \n",
    "- Ã‡atlaÄŸÄ± **uzun eksenine gÃ¶re dÃ¶ndÃ¼rerek** kutula â†’ model daha doÄŸru Ã¶ÄŸrenir.  \n",
    "\n",
    "### B) Birden Fazla KÃ¼Ã§Ã¼k DikdÃ¶rtgen\n",
    "- Ã‡atlak Ã§ok uzun ise, onu **birden fazla kÃ¼Ã§Ã¼k dikdÃ¶rtgen bboxâ€™a bÃ¶l**.  \n",
    "- Ã–rn: 3-4 parÃ§aya bÃ¶l â†’ her parÃ§a ayrÄ± etiketlenir.  \n",
    "- Avantaj: Model uzun ve ince nesneleri daha iyi Ã¶ÄŸrenir.\n",
    "\n",
    "### C) Minimum DikdÃ¶rtgen\n",
    "- Ã‡atlaÄŸÄ± Ã§evreleyen **en kÃ¼Ã§Ã¼k dikdÃ¶rtgeni** Ã§iz.  \n",
    "- EÄŸer Ã§ok yatÄ±ksa, kutu biraz **padding** ile geniÅŸletilebilir â†’ model hem nesneyi hem biraz Ã§evresini gÃ¶rÃ¼r.  \n",
    "\n",
    "\n",
    "## 3ï¸âƒ£ Crop ve EÄŸitim AÃ§Ä±sÄ±ndan\n",
    "- Uzun Ã§atlaÄŸÄ± tek crop iÃ§ine al â†’ padding bÄ±rak.  \n",
    "- Veya parÃ§alar halinde crop al â†’ datasetâ€™i Ã§eÅŸitlendirmiÅŸ olursun.  \n",
    "- Normalize ederken her bboxâ€™un **crop iÃ§indeki koordinatlarÄ±nÄ±** doÄŸru hesapla.\n",
    "\n",
    "\n",
    "## 4ï¸âƒ£ Ã–zet Strateji\n",
    "1. Ã‡atlak uzun ve yatÄ±k â†’ tek dikdÃ¶rtgen veya birden fazla kÃ¼Ã§Ã¼k dikdÃ¶rtgen.  \n",
    "2. Padding bÄ±rak â†’ yol ve Ã§evre bilgisini kaybetme.  \n",
    "3. Rotated bbox destekleyen YOLO sÃ¼rÃ¼mÃ¼ kullan â†’ en doÄŸru sonuÃ§.  \n",
    "4. Datasetâ€™i Ã§eÅŸitlendirmek iÃ§in parÃ§alama ve augmentation uygula.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f470d55",
   "metadata": {},
   "source": [
    "### Åimdi sizlerle bir yolda bulunan tÃ¼mseklerin analizini yapcaÄŸÄ±z.Yani yolda bulunan tÃ¼msekleri etiketleyeceÄŸiz.SonrasÄ±nda ise bu etiketlenmiÅŸ verileri YOLO'ya entegre ettirip yol ve tÃ¼msek olarak etiketleme yapacaÄŸÄ±z.SonrasÄ±nda ise buradan Ã§Ä±kan deÄŸerleri CNN modele koyup daha detaylÄ± analizini yapacaÄŸÄ±z.\n",
    "\n",
    "#### Bu uygulamaya ve Ã§Ã¶zÃ¼me ulaÅŸmak iÃ§in lÃ¼tfen ÅŸu dosya yoluna gidiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9da26f",
   "metadata": {},
   "source": [
    "```python \n",
    "\n",
    "* YOLO\\YOLO\\Uygulamalar\\Uygulama - 1 (Yol - TÃ¼msek)\\yol_tÃ¼msek.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e45e15",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
